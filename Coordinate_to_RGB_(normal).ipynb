{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrVJreJvbcDY",
        "outputId": "76abf5d7-6d4b-4afa-b4e5-21bf1cc414ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import cv2\n",
        "image = cv2.imread(\"/content/drive/MyDrive/sample_dog.jpg\", 1)\n",
        "resized_image = cv2.resize(image, (256, 256))\n",
        "cv2.imwrite(\"/content/drive/MyDrive/resized_dog.png\", resized_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tfw4q833bm0M"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MLP, self).__init__()\n",
        "    self.fcn1 = nn.Linear(2, 256)\n",
        "    self.fcn2 = nn.Linear(256, 256)\n",
        "    self.fcn3 = nn.Linear(256, 128)\n",
        "    self.fcn4 = nn.Linear(128, 3)\n",
        "    self.fc1_bn = nn.BatchNorm1d(128)\n",
        "    self.fc2_bn = nn.BatchNorm1d(256)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.relu(self.fcn1(X))\n",
        "    X = self.fc2_bn(X)\n",
        "    X = self.relu(self.fcn2(X))\n",
        "    X = self.fc2_bn(X)\n",
        "    X = self.relu(self.fcn2(X))\n",
        "    X = self.fc2_bn(X)\n",
        "    X = self.relu(self.fcn2(X))\n",
        "    X = self.fc2_bn(X)\n",
        "    X = self.relu(self.fcn3(X))\n",
        "    X = self.fc1_bn(X)\n",
        "    X = self.sig(self.fcn4(X))\n",
        "    return X\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xx9DDGfSb1MH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, n, img_path):\n",
        "        self.X = []\n",
        "        self.Y = []\n",
        "        image = torchvision.io.read_image(img_path)\n",
        "        _, height, width = image.shape\n",
        "        image = image.numpy()\n",
        "        \n",
        "        for i in range(height):\n",
        "          for j in range(width):\n",
        "            self.X.append(np.array([i, j])/255.0)\n",
        "            self.Y.append(image[:, i, j]/255.0)\n",
        "        self.Y = [l.tolist() for l in self.Y]\n",
        "\n",
        "        if n != None:\n",
        "          self.X = self.X[:n]\n",
        "          self.Y = self.Y[:n]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      idx_sample = self.X[idx]\n",
        "      idx_target = self.Y[idx]\n",
        "      return {\n",
        "          \"x\": torch.tensor(idx_sample, dtype = torch.float),\n",
        "          \"y\": torch.tensor(idx_target, dtype = torch.float),\n",
        "      }\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyPQpY6Yb1__",
        "outputId": "f55285f3-412a-420a-c247-367ca84e6c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1, loss = 0.1530\n",
            "epoch:2, loss = 0.1486\n",
            "epoch:3, loss = 0.1435\n",
            "epoch:4, loss = 0.1382\n",
            "epoch:5, loss = 0.1339\n",
            "epoch:6, loss = 0.1296\n",
            "epoch:7, loss = 0.1240\n",
            "epoch:8, loss = 0.1193\n",
            "epoch:9, loss = 0.1086\n",
            "epoch:10, loss = 0.1020\n",
            "epoch:11, loss = 0.0952\n",
            "epoch:12, loss = 0.0884\n",
            "epoch:13, loss = 0.0810\n",
            "epoch:14, loss = 0.0742\n",
            "epoch:15, loss = 0.0685\n",
            "epoch:16, loss = 0.0633\n",
            "epoch:17, loss = 0.0579\n",
            "epoch:18, loss = 0.0526\n",
            "epoch:19, loss = 0.0482\n",
            "epoch:20, loss = 0.0445\n",
            "epoch:21, loss = 0.0422\n",
            "epoch:22, loss = 0.0388\n",
            "epoch:23, loss = 0.0362\n",
            "epoch:24, loss = 0.0344\n",
            "epoch:25, loss = 0.0333\n",
            "epoch:26, loss = 0.0312\n",
            "epoch:27, loss = 0.0301\n",
            "epoch:28, loss = 0.0290\n",
            "epoch:29, loss = 0.0276\n",
            "epoch:30, loss = 0.0266\n",
            "epoch:31, loss = 0.0261\n",
            "epoch:32, loss = 0.0249\n",
            "epoch:33, loss = 0.0251\n",
            "epoch:34, loss = 0.0258\n",
            "epoch:35, loss = 0.0253\n",
            "epoch:36, loss = 0.0234\n",
            "epoch:37, loss = 0.0234\n",
            "epoch:38, loss = 0.0215\n",
            "epoch:39, loss = 0.0209\n",
            "epoch:40, loss = 0.0212\n",
            "epoch:41, loss = 0.0219\n",
            "epoch:42, loss = 0.0203\n",
            "epoch:43, loss = 0.0195\n",
            "epoch:44, loss = 0.0188\n",
            "epoch:45, loss = 0.0184\n",
            "epoch:46, loss = 0.0188\n",
            "epoch:47, loss = 0.0204\n",
            "epoch:48, loss = 0.0197\n",
            "epoch:49, loss = 0.0180\n",
            "epoch:50, loss = 0.0177\n",
            "epoch:51, loss = 0.0176\n",
            "epoch:52, loss = 0.0176\n",
            "epoch:53, loss = 0.0172\n",
            "epoch:54, loss = 0.0166\n",
            "epoch:55, loss = 0.0161\n",
            "epoch:56, loss = 0.0152\n",
            "epoch:57, loss = 0.0154\n",
            "epoch:58, loss = 0.0151\n",
            "epoch:59, loss = 0.0145\n",
            "epoch:60, loss = 0.0155\n",
            "epoch:61, loss = 0.0159\n",
            "epoch:62, loss = 0.0155\n",
            "epoch:63, loss = 0.0147\n",
            "epoch:64, loss = 0.0138\n",
            "epoch:65, loss = 0.0136\n",
            "epoch:66, loss = 0.0139\n",
            "epoch:67, loss = 0.0139\n",
            "epoch:68, loss = 0.0141\n",
            "epoch:69, loss = 0.0144\n",
            "epoch:70, loss = 0.0136\n",
            "epoch:71, loss = 0.0131\n",
            "epoch:72, loss = 0.0136\n",
            "epoch:73, loss = 0.0140\n",
            "epoch:74, loss = 0.0138\n",
            "epoch:75, loss = 0.0138\n",
            "epoch:76, loss = 0.0133\n",
            "epoch:77, loss = 0.0126\n",
            "epoch:78, loss = 0.0129\n",
            "epoch:79, loss = 0.0133\n",
            "epoch:80, loss = 0.0131\n",
            "epoch:81, loss = 0.0125\n",
            "epoch:82, loss = 0.0120\n",
            "epoch:83, loss = 0.0133\n",
            "epoch:84, loss = 0.0124\n",
            "epoch:85, loss = 0.0121\n",
            "epoch:86, loss = 0.0125\n",
            "epoch:87, loss = 0.0126\n",
            "epoch:88, loss = 0.0119\n",
            "epoch:89, loss = 0.0122\n",
            "epoch:90, loss = 0.0126\n",
            "epoch:91, loss = 0.0123\n",
            "epoch:92, loss = 0.0139\n",
            "epoch:93, loss = 0.0120\n",
            "epoch:94, loss = 0.0117\n",
            "epoch:95, loss = 0.0111\n",
            "epoch:96, loss = 0.0105\n",
            "epoch:97, loss = 0.0116\n",
            "epoch:98, loss = 0.0114\n",
            "epoch:99, loss = 0.0108\n",
            "epoch:100, loss = 0.0108\n",
            "epoch:101, loss = 0.0107\n",
            "epoch:102, loss = 0.0108\n",
            "epoch:103, loss = 0.0109\n",
            "epoch:104, loss = 0.0115\n",
            "epoch:105, loss = 0.0102\n",
            "epoch:106, loss = 0.0104\n",
            "epoch:107, loss = 0.0099\n",
            "epoch:108, loss = 0.0098\n",
            "epoch:109, loss = 0.0097\n",
            "epoch:110, loss = 0.0098\n",
            "epoch:111, loss = 0.0100\n",
            "epoch:112, loss = 0.0113\n",
            "epoch:113, loss = 0.0107\n",
            "epoch:114, loss = 0.0112\n",
            "epoch:115, loss = 0.0104\n",
            "epoch:116, loss = 0.0109\n",
            "epoch:117, loss = 0.0108\n",
            "epoch:118, loss = 0.0099\n",
            "epoch:119, loss = 0.0104\n",
            "epoch:120, loss = 0.0105\n",
            "epoch:121, loss = 0.0096\n",
            "epoch:122, loss = 0.0094\n",
            "epoch:123, loss = 0.0091\n",
            "epoch:124, loss = 0.0105\n",
            "epoch:125, loss = 0.0097\n",
            "epoch:126, loss = 0.0090\n",
            "epoch:127, loss = 0.0091\n",
            "epoch:128, loss = 0.0091\n",
            "epoch:129, loss = 0.0093\n",
            "epoch:130, loss = 0.0101\n",
            "epoch:131, loss = 0.0099\n",
            "epoch:132, loss = 0.0097\n",
            "epoch:133, loss = 0.0097\n",
            "epoch:134, loss = 0.0089\n",
            "epoch:135, loss = 0.0097\n",
            "epoch:136, loss = 0.0096\n",
            "epoch:137, loss = 0.0103\n",
            "epoch:138, loss = 0.0102\n",
            "epoch:139, loss = 0.0095\n",
            "epoch:140, loss = 0.0088\n",
            "epoch:141, loss = 0.0085\n",
            "epoch:142, loss = 0.0089\n",
            "epoch:143, loss = 0.0081\n",
            "epoch:144, loss = 0.0083\n",
            "epoch:145, loss = 0.0088\n",
            "epoch:146, loss = 0.0079\n",
            "epoch:147, loss = 0.0090\n",
            "epoch:148, loss = 0.0087\n",
            "epoch:149, loss = 0.0094\n",
            "epoch:150, loss = 0.0087\n",
            "epoch:151, loss = 0.0081\n",
            "epoch:152, loss = 0.0088\n",
            "epoch:153, loss = 0.0084\n",
            "epoch:154, loss = 0.0087\n",
            "epoch:155, loss = 0.0091\n",
            "epoch:156, loss = 0.0090\n",
            "epoch:157, loss = 0.0097\n",
            "epoch:158, loss = 0.0082\n",
            "epoch:159, loss = 0.0085\n",
            "epoch:160, loss = 0.0085\n",
            "epoch:161, loss = 0.0085\n",
            "epoch:162, loss = 0.0090\n",
            "epoch:163, loss = 0.0099\n",
            "epoch:164, loss = 0.0088\n",
            "epoch:165, loss = 0.0090\n",
            "epoch:166, loss = 0.0091\n",
            "epoch:167, loss = 0.0080\n",
            "epoch:168, loss = 0.0080\n",
            "epoch:169, loss = 0.0087\n",
            "epoch:170, loss = 0.0081\n",
            "epoch:171, loss = 0.0085\n",
            "epoch:172, loss = 0.0086\n",
            "epoch:173, loss = 0.0092\n",
            "epoch:174, loss = 0.0093\n",
            "epoch:175, loss = 0.0081\n",
            "epoch:176, loss = 0.0077\n",
            "epoch:177, loss = 0.0083\n",
            "epoch:178, loss = 0.0079\n",
            "epoch:179, loss = 0.0075\n",
            "epoch:180, loss = 0.0079\n",
            "epoch:181, loss = 0.0090\n",
            "epoch:182, loss = 0.0075\n",
            "epoch:183, loss = 0.0078\n",
            "epoch:184, loss = 0.0078\n",
            "epoch:185, loss = 0.0072\n",
            "epoch:186, loss = 0.0082\n",
            "epoch:187, loss = 0.0075\n",
            "epoch:188, loss = 0.0079\n",
            "epoch:189, loss = 0.0075\n",
            "epoch:190, loss = 0.0069\n",
            "epoch:191, loss = 0.0075\n",
            "epoch:192, loss = 0.0069\n",
            "epoch:193, loss = 0.0076\n",
            "epoch:194, loss = 0.0068\n",
            "epoch:195, loss = 0.0070\n",
            "epoch:196, loss = 0.0071\n",
            "epoch:197, loss = 0.0070\n",
            "epoch:198, loss = 0.0069\n",
            "epoch:199, loss = 0.0068\n",
            "epoch:200, loss = 0.0080\n",
            "epoch:201, loss = 0.0079\n",
            "epoch:202, loss = 0.0086\n",
            "epoch:203, loss = 0.0084\n",
            "epoch:204, loss = 0.0076\n",
            "epoch:205, loss = 0.0091\n",
            "epoch:206, loss = 0.0074\n",
            "epoch:207, loss = 0.0075\n",
            "epoch:208, loss = 0.0067\n",
            "epoch:209, loss = 0.0071\n",
            "epoch:210, loss = 0.0070\n",
            "epoch:211, loss = 0.0063\n",
            "epoch:212, loss = 0.0078\n",
            "epoch:213, loss = 0.0079\n",
            "epoch:214, loss = 0.0075\n",
            "epoch:215, loss = 0.0062\n",
            "epoch:216, loss = 0.0066\n",
            "epoch:217, loss = 0.0064\n",
            "epoch:218, loss = 0.0063\n",
            "epoch:219, loss = 0.0070\n",
            "epoch:220, loss = 0.0070\n",
            "epoch:221, loss = 0.0060\n",
            "epoch:222, loss = 0.0062\n",
            "epoch:223, loss = 0.0066\n",
            "epoch:224, loss = 0.0073\n",
            "epoch:225, loss = 0.0070\n",
            "epoch:226, loss = 0.0062\n",
            "epoch:227, loss = 0.0065\n",
            "epoch:228, loss = 0.0066\n",
            "epoch:229, loss = 0.0063\n",
            "epoch:230, loss = 0.0061\n",
            "epoch:231, loss = 0.0066\n",
            "epoch:232, loss = 0.0069\n",
            "epoch:233, loss = 0.0065\n",
            "epoch:234, loss = 0.0068\n",
            "epoch:235, loss = 0.0067\n",
            "epoch:236, loss = 0.0068\n",
            "epoch:237, loss = 0.0072\n",
            "epoch:238, loss = 0.0066\n",
            "epoch:239, loss = 0.0072\n",
            "epoch:240, loss = 0.0060\n",
            "epoch:241, loss = 0.0066\n",
            "epoch:242, loss = 0.0062\n",
            "epoch:243, loss = 0.0062\n",
            "epoch:244, loss = 0.0070\n",
            "epoch:245, loss = 0.0059\n",
            "epoch:246, loss = 0.0057\n",
            "epoch:247, loss = 0.0066\n",
            "epoch:248, loss = 0.0063\n",
            "epoch:249, loss = 0.0062\n",
            "epoch:250, loss = 0.0058\n",
            "epoch:251, loss = 0.0071\n",
            "epoch:252, loss = 0.0067\n",
            "epoch:253, loss = 0.0057\n",
            "epoch:254, loss = 0.0066\n",
            "epoch:255, loss = 0.0065\n",
            "epoch:256, loss = 0.0060\n",
            "epoch:257, loss = 0.0068\n",
            "epoch:258, loss = 0.0067\n",
            "epoch:259, loss = 0.0064\n",
            "epoch:260, loss = 0.0072\n",
            "epoch:261, loss = 0.0074\n",
            "epoch:262, loss = 0.0078\n",
            "epoch:263, loss = 0.0066\n",
            "epoch:264, loss = 0.0070\n",
            "epoch:265, loss = 0.0061\n",
            "epoch:266, loss = 0.0056\n",
            "epoch:267, loss = 0.0063\n",
            "epoch:268, loss = 0.0064\n",
            "epoch:269, loss = 0.0063\n",
            "epoch:270, loss = 0.0060\n",
            "epoch:271, loss = 0.0065\n",
            "epoch:272, loss = 0.0065\n",
            "epoch:273, loss = 0.0073\n",
            "epoch:274, loss = 0.0065\n",
            "epoch:275, loss = 0.0060\n",
            "epoch:276, loss = 0.0060\n",
            "epoch:277, loss = 0.0062\n",
            "epoch:278, loss = 0.0063\n",
            "epoch:279, loss = 0.0066\n",
            "epoch:280, loss = 0.0065\n",
            "epoch:281, loss = 0.0069\n",
            "epoch:282, loss = 0.0064\n",
            "epoch:283, loss = 0.0078\n",
            "epoch:284, loss = 0.0066\n",
            "epoch:285, loss = 0.0067\n",
            "epoch:286, loss = 0.0066\n",
            "epoch:287, loss = 0.0064\n",
            "epoch:288, loss = 0.0061\n",
            "epoch:289, loss = 0.0065\n",
            "epoch:290, loss = 0.0059\n",
            "epoch:291, loss = 0.0070\n",
            "epoch:292, loss = 0.0063\n",
            "epoch:293, loss = 0.0068\n",
            "epoch:294, loss = 0.0068\n",
            "epoch:295, loss = 0.0065\n",
            "epoch:296, loss = 0.0072\n",
            "epoch:297, loss = 0.0066\n",
            "epoch:298, loss = 0.0060\n",
            "epoch:299, loss = 0.0060\n",
            "epoch:300, loss = 0.0059\n",
            "epoch:301, loss = 0.0055\n",
            "epoch:302, loss = 0.0063\n",
            "epoch:303, loss = 0.0062\n",
            "epoch:304, loss = 0.0060\n",
            "epoch:305, loss = 0.0065\n",
            "epoch:306, loss = 0.0061\n",
            "epoch:307, loss = 0.0057\n",
            "epoch:308, loss = 0.0060\n",
            "epoch:309, loss = 0.0066\n",
            "epoch:310, loss = 0.0057\n",
            "epoch:311, loss = 0.0065\n",
            "epoch:312, loss = 0.0066\n",
            "epoch:313, loss = 0.0060\n",
            "epoch:314, loss = 0.0066\n",
            "epoch:315, loss = 0.0059\n",
            "epoch:316, loss = 0.0062\n",
            "epoch:317, loss = 0.0059\n",
            "epoch:318, loss = 0.0059\n",
            "epoch:319, loss = 0.0059\n",
            "epoch:320, loss = 0.0063\n",
            "epoch:321, loss = 0.0062\n",
            "epoch:322, loss = 0.0061\n",
            "epoch:323, loss = 0.0061\n",
            "epoch:324, loss = 0.0063\n",
            "epoch:325, loss = 0.0060\n",
            "epoch:326, loss = 0.0060\n",
            "epoch:327, loss = 0.0064\n",
            "epoch:328, loss = 0.0062\n",
            "epoch:329, loss = 0.0060\n",
            "epoch:330, loss = 0.0057\n",
            "epoch:331, loss = 0.0056\n",
            "epoch:332, loss = 0.0074\n",
            "epoch:333, loss = 0.0062\n",
            "epoch:334, loss = 0.0055\n",
            "epoch:335, loss = 0.0055\n",
            "epoch:336, loss = 0.0053\n",
            "epoch:337, loss = 0.0052\n",
            "epoch:338, loss = 0.0060\n",
            "epoch:339, loss = 0.0057\n",
            "epoch:340, loss = 0.0053\n",
            "epoch:341, loss = 0.0056\n",
            "epoch:342, loss = 0.0059\n",
            "epoch:343, loss = 0.0048\n",
            "epoch:344, loss = 0.0053\n",
            "epoch:345, loss = 0.0056\n",
            "epoch:346, loss = 0.0057\n",
            "epoch:347, loss = 0.0060\n",
            "epoch:348, loss = 0.0058\n",
            "epoch:349, loss = 0.0055\n",
            "epoch:350, loss = 0.0052\n",
            "epoch:351, loss = 0.0053\n",
            "epoch:352, loss = 0.0055\n",
            "epoch:353, loss = 0.0057\n",
            "epoch:354, loss = 0.0057\n",
            "epoch:355, loss = 0.0059\n",
            "epoch:356, loss = 0.0063\n",
            "epoch:357, loss = 0.0056\n",
            "epoch:358, loss = 0.0055\n",
            "epoch:359, loss = 0.0062\n",
            "epoch:360, loss = 0.0063\n",
            "epoch:361, loss = 0.0061\n",
            "epoch:362, loss = 0.0059\n",
            "epoch:363, loss = 0.0056\n",
            "epoch:364, loss = 0.0053\n",
            "epoch:365, loss = 0.0054\n",
            "epoch:366, loss = 0.0057\n",
            "epoch:367, loss = 0.0053\n",
            "epoch:368, loss = 0.0057\n",
            "epoch:369, loss = 0.0057\n",
            "epoch:370, loss = 0.0055\n",
            "epoch:371, loss = 0.0054\n",
            "epoch:372, loss = 0.0050\n",
            "epoch:373, loss = 0.0053\n",
            "epoch:374, loss = 0.0054\n",
            "epoch:375, loss = 0.0062\n",
            "epoch:376, loss = 0.0066\n",
            "epoch:377, loss = 0.0049\n",
            "epoch:378, loss = 0.0049\n",
            "epoch:379, loss = 0.0056\n",
            "epoch:380, loss = 0.0057\n",
            "epoch:381, loss = 0.0060\n",
            "epoch:382, loss = 0.0060\n",
            "epoch:383, loss = 0.0071\n",
            "epoch:384, loss = 0.0055\n",
            "epoch:385, loss = 0.0062\n",
            "epoch:386, loss = 0.0059\n",
            "epoch:387, loss = 0.0056\n",
            "epoch:388, loss = 0.0052\n",
            "epoch:389, loss = 0.0055\n",
            "epoch:390, loss = 0.0060\n",
            "epoch:391, loss = 0.0051\n",
            "epoch:392, loss = 0.0051\n",
            "epoch:393, loss = 0.0051\n",
            "epoch:394, loss = 0.0055\n",
            "epoch:395, loss = 0.0052\n",
            "epoch:396, loss = 0.0052\n",
            "epoch:397, loss = 0.0053\n",
            "epoch:398, loss = 0.0051\n",
            "epoch:399, loss = 0.0048\n",
            "epoch:400, loss = 0.0044\n",
            "epoch:401, loss = 0.0048\n",
            "epoch:402, loss = 0.0050\n",
            "epoch:403, loss = 0.0064\n",
            "epoch:404, loss = 0.0050\n",
            "epoch:405, loss = 0.0048\n",
            "epoch:406, loss = 0.0049\n",
            "epoch:407, loss = 0.0044\n",
            "epoch:408, loss = 0.0049\n",
            "epoch:409, loss = 0.0055\n",
            "epoch:410, loss = 0.0053\n",
            "epoch:411, loss = 0.0049\n",
            "epoch:412, loss = 0.0050\n",
            "epoch:413, loss = 0.0050\n",
            "epoch:414, loss = 0.0053\n",
            "epoch:415, loss = 0.0050\n",
            "epoch:416, loss = 0.0047\n",
            "epoch:417, loss = 0.0045\n",
            "epoch:418, loss = 0.0050\n",
            "epoch:419, loss = 0.0046\n",
            "epoch:420, loss = 0.0047\n",
            "epoch:421, loss = 0.0056\n",
            "epoch:422, loss = 0.0053\n",
            "epoch:423, loss = 0.0048\n",
            "epoch:424, loss = 0.0057\n",
            "epoch:425, loss = 0.0048\n",
            "epoch:426, loss = 0.0069\n",
            "epoch:427, loss = 0.0053\n",
            "epoch:428, loss = 0.0041\n",
            "epoch:429, loss = 0.0043\n",
            "epoch:430, loss = 0.0050\n",
            "epoch:431, loss = 0.0052\n",
            "epoch:432, loss = 0.0049\n",
            "epoch:433, loss = 0.0054\n",
            "epoch:434, loss = 0.0043\n",
            "epoch:435, loss = 0.0044\n",
            "epoch:436, loss = 0.0053\n",
            "epoch:437, loss = 0.0052\n",
            "epoch:438, loss = 0.0044\n",
            "epoch:439, loss = 0.0043\n",
            "epoch:440, loss = 0.0049\n",
            "epoch:441, loss = 0.0042\n",
            "epoch:442, loss = 0.0049\n",
            "epoch:443, loss = 0.0046\n",
            "epoch:444, loss = 0.0044\n",
            "epoch:445, loss = 0.0044\n",
            "epoch:446, loss = 0.0045\n",
            "epoch:447, loss = 0.0050\n",
            "epoch:448, loss = 0.0051\n",
            "epoch:449, loss = 0.0051\n",
            "epoch:450, loss = 0.0053\n",
            "epoch:451, loss = 0.0058\n",
            "epoch:452, loss = 0.0051\n",
            "epoch:453, loss = 0.0048\n",
            "epoch:454, loss = 0.0049\n",
            "epoch:455, loss = 0.0053\n",
            "epoch:456, loss = 0.0044\n",
            "epoch:457, loss = 0.0046\n",
            "epoch:458, loss = 0.0045\n",
            "epoch:459, loss = 0.0044\n",
            "epoch:460, loss = 0.0043\n",
            "epoch:461, loss = 0.0043\n",
            "epoch:462, loss = 0.0048\n",
            "epoch:463, loss = 0.0052\n",
            "epoch:464, loss = 0.0046\n",
            "epoch:465, loss = 0.0047\n",
            "epoch:466, loss = 0.0042\n",
            "epoch:467, loss = 0.0045\n",
            "epoch:468, loss = 0.0047\n",
            "epoch:469, loss = 0.0044\n",
            "epoch:470, loss = 0.0046\n",
            "epoch:471, loss = 0.0053\n",
            "epoch:472, loss = 0.0052\n",
            "epoch:473, loss = 0.0052\n",
            "epoch:474, loss = 0.0047\n",
            "epoch:475, loss = 0.0045\n",
            "epoch:476, loss = 0.0045\n",
            "epoch:477, loss = 0.0051\n",
            "epoch:478, loss = 0.0045\n",
            "epoch:479, loss = 0.0046\n",
            "epoch:480, loss = 0.0047\n",
            "epoch:481, loss = 0.0051\n",
            "epoch:482, loss = 0.0050\n",
            "epoch:483, loss = 0.0048\n",
            "epoch:484, loss = 0.0046\n",
            "epoch:485, loss = 0.0042\n",
            "epoch:486, loss = 0.0047\n",
            "epoch:487, loss = 0.0049\n",
            "epoch:488, loss = 0.0049\n",
            "epoch:489, loss = 0.0048\n",
            "epoch:490, loss = 0.0047\n",
            "epoch:491, loss = 0.0046\n",
            "epoch:492, loss = 0.0043\n",
            "epoch:493, loss = 0.0045\n",
            "epoch:494, loss = 0.0045\n",
            "epoch:495, loss = 0.0045\n",
            "epoch:496, loss = 0.0042\n",
            "epoch:497, loss = 0.0046\n",
            "epoch:498, loss = 0.0051\n",
            "epoch:499, loss = 0.0042\n",
            "epoch:500, loss = 0.0042\n"
          ]
        }
      ],
      "source": [
        "dump_path = \"/content/drive/MyDrive/dog_dump\"\n",
        "img_path = \"/content/drive/MyDrive/resized_dog.png\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "dataset = CustomDataset(None, img_path)\n",
        "train_loader  = torch.utils.data.DataLoader(dataset, batch_size = 512)\n",
        "\n",
        "X = []\n",
        "image = torchvision.io.read_image(img_path)\n",
        "_, height, width = image.shape\n",
        "image = image.numpy()\n",
        "for i in range(height):\n",
        "  for j in range(width):\n",
        "    X.append(np.array([i, j])/255.0)\n",
        "picture = torch.FloatTensor(X).to(device = device)\n",
        "\n",
        "\n",
        "num_epochs = 500\n",
        "losses = []\n",
        "learning_rate = 0.0001\n",
        "model = MLP()\n",
        "model = model.to(device=device)\n",
        "model.train()\n",
        "criterian = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  for data in train_loader:\n",
        "    xtrain = data[\"x\"].to(device = device)\n",
        "    ytrain = data[\"y\"].to(device = device)\n",
        "    pred = model(xtrain)\n",
        "    loss = criterian(pred, ytrain)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  losses.append(loss.item())\n",
        "  if epoch%5==0:\n",
        "    with torch.no_grad():\n",
        "      picture_pred = model(picture)\n",
        "      picture_pred = picture_pred*255\n",
        "      picture_pred = torch.reshape(picture_pred, (256, 256, 3))\n",
        "      res = picture_pred.detach().cpu().numpy()\n",
        "      res = res.astype(np.uint8)\n",
        "      res = Image.fromarray(res, 'RGB')\n",
        "      res.save(f\"{dump_path}/pred_dog_{epoch}.jpg\")\n",
        "  print(f\"epoch:{epoch}, loss = {loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "VigzzmUpb6uR",
        "outputId": "b9c5e1fe-0413-4605-8120-0db35afbcbf9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xcdZ3/8dcnmczknrRNek1v0EJpuVQIRQSEBcWCSt0VFGRX8ccurrusuquusPpDxb2xP1fUFV1wRRF1wWVhrVDlLriA0AClpffQW5JekrRpLs198vn9MSdxmk7TpM3ppJn38/HIo2fOZeZzQsg73+/3nO8xd0dERGSwrHQXICIiY5MCQkREUlJAiIhISgoIERFJSQEhIiIpKSBERCSlUAPCzJaa2UYzqzazW1Jsf6eZvWZmvWZ29aBts8zsCTNbb2brzGxOmLWKiMjBQgsIM8sG7gKuABYC15nZwkG77QBuAH6W4i1+DPw/dz8NWALUh1WriIgcKhLiey8Bqt19C4CZPQAsA9b17+Du24JtfckHBkEScfcng/3aQqxTRERSCDMgZgA1Sa9rgfOGeewpwH4zexiYCzwF3OLu8cMdUFZW5nPmzDnKUkVEMtOrr77a6O7lqbaFGRDHIgJcBLyNRDfUgyS6on6QvJOZ3QTcBDBr1iyqqqqOb5UiIic4M9t+uG1hDlLXATOTXlcE64ajFljl7lvcvRf4H+DswTu5+z3uXunuleXlKQNQRESOUpgBsRKYb2ZzzSwKXAssH8GxpWbW/1v/UpLGLkREJHyhBUTwl//NwOPAeuDn7r7WzG43s6sAzOxcM6sFrgHuNrO1wbFx4HPA02a2BjDg+2HVKiIih7LxMt13ZWWlawxCRGRkzOxVd69MtU13UouISEoKCBERSUkBISIiKWV8QLR09vDNpzaxqmZ/uksRERlTMj4g3OGbT22matu+dJciIjKmZHxAFOdGiEWyqG/tSncpIiJjSsYHhJlRXhSjvqUz3aWIiIwpGR8QAJOLYjS0qQUhIpJMAQFMLsqlvkUBISKSTAEBiS4mjUGIiBxEAUGii6m5o4eu3sM+bkJEJOMoIIDJxTEAGtSKEBEZoIAg0cUECggRkWQKCBKD1IDGIUREkiggSIxBgAJCRCSZAgKYWBDFTF1MIiLJFBBAJDuLSQUxGlp1N7WISD8FRCAx3YZaECIi/UINCDNbamYbzazazG5Jsf2dZvaamfWa2dUpthebWa2ZfSfMOkHTbYiIDBZaQJhZNnAXcAWwELjOzBYO2m0HcAPws8O8zdeA58OqMdlktSBERA4SZgtiCVDt7lvcvRt4AFiWvIO7b3P31UDf4IPN7BxgCvBEiDUOKC+K0djWRV+fH4+PExEZ88IMiBlATdLr2mDdEZlZFvCvwOeOsN9NZlZlZlUNDQ1HXSgkWhC9fU5Te/cxvY+IyHgxVgep/wJY4e61Q+3k7ve4e6W7V5aXlx/TB5brZjkRkYNEQnzvOmBm0uuKYN1wnA9cZGZ/ARQCUTNrc/dDBrpHS/J8TKdNC+tTREROHGEGxEpgvpnNJREM1wIfGc6B7n59/7KZ3QBUhhkOoLupRUQGC62Lyd17gZuBx4H1wM/dfa2Z3W5mVwGY2blmVgtcA9xtZmvDqudIygcCQjfLiYhAuC0I3H0FsGLQutuSlleS6Hoa6j1+BPwohPIOkh+NUBiLaLoNEZHAWB2kTgs9WU5E5PcUEEnKi2JqQYiIBBQQSRJ3U2sMQkQEFBAHmVqcy56WLtx1N7WIiAIiydSSXDp64rR09Ka7FBGRtFNAJJlakribere6mUREFBDJphYnAmJXc0eaKxERST8FRJL+FsQetSBERBQQySYHE/btbtalriIiCogk0UgWJXk57D2ggBARUUAMUlYYpVGPHhURUUAMVlYYo7FVDw0SEVFADFIWPHpURCTTKSAGKSuI0qCAEBFRQAxWVhijtbOXzp54uksREUkrBcQgZcGDg/Ye0DiEiGQ2BcQgZYVBQKibSUQyXKgBYWZLzWyjmVWb2SHPlDazd5rZa2bWa2ZXJ61fbGYvmdlaM1ttZh8Os85kZYVRAA1Ui0jGCy0gzCwbuAu4AlgIXGdmCwfttgO4AfjZoPXtwEfdfRGwFPimmZWGVWuy/haELnUVkUwX5jOplwDV7r4FwMweAJYB6/p3cPdtwba+5APdfVPS8k4zqwfKgf0h1gv8PiB0JZOIZLowu5hmADVJr2uDdSNiZkuAKPDWKNU1pLxoNgXRbHUxiUjGG9OD1GY2Dbgf+Li796XYfpOZVZlZVUNDw6h9buJmOXUxiUhmCzMg6oCZSa8rgnXDYmbFwGPAF939d6n2cfd73L3S3SvLy8uPqdhkJXk5tHT0jNr7iYiciMIMiJXAfDOba2ZR4Fpg+XAODPZ/BPixuz8UYo0p5eVk09GtG+VEJLOFFhDu3gvcDDwOrAd+7u5rzex2M7sKwMzONbNa4BrgbjNbGxz+IeCdwA1mtir4WhxWrYPlR7Np79FzqUUks4V5FRPuvgJYMWjdbUnLK0l0PQ0+7ifAT8KsbSj50Qjt3e3p+ngRkTFhTA9Sp0teVF1MIiIKiBTyo9m0KyBEJMMpIFJQC0JERAGRUn5OhO54H73xQ269EBHJGAqIFPKj2QB06JkQIpLBFBAp5PUHhLqZRCSDKSBS6G9BaKBaRDKZAiIFBYSIiAIipbxo4v7BDt1NLSIZTAGRgloQIiIKiJQKY4kWRFunWhAikrkUECmU5OUA0Kwpv0UkgykgUijNTwTEfgWEiGQwBUQKeTnZRLOz2N+ugBCRzKWASMHMKM7LUReTiGQ0BcRhlObn0Nyh51KLSOZSQBxGiVoQIpLhFBCHUZqXozEIEclooQaEmS01s41mVm1mt6TY/k4ze83Mes3s6kHbPmZmm4Ovj4VZZypqQYhIpgstIMwsG7gLuAJYCFxnZgsH7bYDuAH42aBjJwJfBs4DlgBfNrMJYdWaSkl+Ds1qQYhIBguzBbEEqHb3Le7eDTwALEvewd23uftqYPCTed4DPOnu+9y9CXgSWBpirYcoycuhtatXDw0SkYwVZkDMAGqSXtcG68I+dlSUBndTt2i6DRHJUCf0ILWZ3WRmVWZW1dDQMKrvXZofBWB/uy51FZHMFGZA1AEzk15XBOtG7Vh3v8fdK929sry8/KgLTUXzMYlIpgszIFYC881srplFgWuB5cM89nHgcjObEAxOXx6sO25KNB+TiGS40ALC3XuBm0n8Yl8P/Nzd15rZ7WZ2FYCZnWtmtcA1wN1mtjY4dh/wNRIhsxK4PVh33PS3IFoUECKSoSJhvrm7rwBWDFp3W9LyShLdR6mOvRe4N8z6htI/SK2b5UQkU53Qg9RhKlZAiEiGU0AcRk52FoWxiAapRSRjKSCGUJKXw37N6CoiGUoBMYSSvBwNUotIxlJADKE0XzO6ikjmUkAMQTO6ikgmU0AMoTQ/RzfKiUjGUkAMoTgvMeW3u6e7FBGR404BMYTSvCjd8T46ezTlt4hkHgXEEEoH5mPSpa4iknkUEEPQjK4ikskUEEPQfEwikskUEEPQfEwikskUEEPoH4PQ3dQikomGFRBmVmBmWcHyKWZ2lZnlhFta+vWPQWiQWkQy0XBbEM8DuWY2A3gC+BPgR2EVNVYUxiJkZ5kGqUUkIw03IMzd24E/Ar7r7tcAi8Ira2wws8SMrhqDEJEMNOyAMLPzgeuBx4J12cM4aKmZbTSzajO7JcX2mJk9GGx/2czmBOtzzOw+M1tjZuvN7NZh1jnqSjUfk4hkqOEGxGeAW4FHgudKnwQ8O9QBZpYN3AVcASwErjOzhYN2uxFocvd5wJ3AHcH6a4CYu58BnAN8oj88jreSfAWEiGSmYT2T2t2fA54DCAarG939U0c4bAlQ7e5bguMeAJYB65L2WQZ8JVh+CPiOmRngQIGZRYA8oBtoGU6to60kL4e9bRqkFpHMM9yrmH5mZsVmVgC8Cawzs88f4bAZQE3S69pgXcp93L0XaAYmkQiLA8AuYAfwdXffN5xaR5u6mEQkUw23i2mhu7cAHwB+BcwlcSVTWJYAcWB68FmfDbq1DmJmN5lZlZlVNTQ0hFJIYpBaLQgRyTzDDYic4L6HDwDL3b2HRDfQUOqAmUmvK4J1KfcJupNKgL3AR4Bfu3uPu9cDLwCVgz/A3e9x90p3rywvLx/mqYxMSX6U1q5e4n2a8ltEMstwA+JuYBtQADxvZrM58pjASmC+mc01syhwLbB80D7LgY8Fy1cDz3ji4Qs7gEshcZMe8HZgwzBrHVUleTm4Q2unuplEJLMMKyDc/dvuPsPdr/SE7cAfHOGYXuBm4HFgPfDz4Aqo283sqmC3HwCTzKwa+Bug/1LYu4BCM1tLImh+6O6rR3x2o6BUM7qKSIYa1lVMZlYCfBl4Z7DqOeB2EoPKh+XuK4AVg9bdlrTcSeKS1sHHtaVanw4Dz4Ro72H2pDQXIyJyHA23i+leoBX4UPDVAvwwrKLGkt/Px6QWhIhklmG1IICT3f2DSa+/amarwihorOlvQaiLSUQyzXBbEB1mdmH/CzO7AOgIp6Sxpf+ZEM261FVEMsxwWxB/Dvw4GIsAaOL3Vx+Na3rsqIhkquFOtfEGcJaZFQevW8zsM0Bariw6nmKRbPJysjWjq4hknBE9Uc7dW4I7qiFxWWpGKNWEfSKSgY7lkaM2alWMcSV5ObqKSUQyzrEERMbMPVGSl0OzuphEJMMMOQZhZq2kDgIjMQ13RijNz2FbY3u6yxAROa6GDAh3LzpehYxliS4mXeYqIpnlWLqYMkZpfpSm9h4S8wiKiGQGBcQwlBVG6e7to62rN92liIgcNwqIYSgrjAHQqEePikgGUUAMQ39ANLR2pbkSEZHjRwExDL9vQSggRCRzKCCGoawoCiggRCSzKCCGYVJBjCyDRnUxiUgGUUAMQ3aWMbEgSoMGqUUkg4QaEGa21Mw2mlm1md2SYnvMzB4Mtr9sZnOStp1pZi+Z2VozW2NmuWHWeiRlhTF1MYlIRgktIMwsG7gLuAJYCFxnZgsH7XYj0OTu84A7gTuCYyPAT4A/d/dFwCVAWidDKiuM6SomEckoYbYglgDV7r7F3buBB4Blg/ZZBtwXLD8EXGZmBlwOrA6eQ4G773X3eIi1HlFZYVQtCBHJKGEGxAygJul1bbAu5T7u3gs0A5OAUwA3s8fN7DUz+9sQ6xyW/i4mTbchIpliuI8cPd4iwIXAuUA78LSZveruTyfvZGY3ATcBzJo1K9SCyotidPb0caA7TmFsrH7bRERGT5gtiDpgZtLrimBdyn2CcYcSYC+J1sbz7t7o7u3ACuDswR/g7ve4e6W7V5aXl4dwCr83cLOcxiFEJEOEGRArgflmNtfMosC1wPJB+ywHPhYsXw0844k+nMeBM8wsPwiOi4F1IdZ6RGVFuptaRDJLaH0l7t5rZjeT+GWfDdzr7mvN7Hagyt2XAz8A7jezamAfiRDB3ZvM7BskQsaBFe7+WFi1DkdZYeJual3JJCKZItTOdHdfQaJ7KHndbUnLncA1hzn2JyQudR0TyjUfk4hkGN1JPUwTC6KYobupRSRjKCCGKZKdxcR83QshIplDATECZYUxXcUkIhlDATECZUVRGtSCEJEMoYAYAU3YJyKZRAExAokuJg1Si0hmUECMQFlhjI6eOAe6etNdiohI6BQQI1Cuu6lFJIMoIEag/25qBYSIZAIFxAj0T9in6TZEJBMoIEZgcnEiIOoVECKSARQQI1BWECMayaKuqSPdpYiIhE4BMQJZWUZFaR61CggRyQAKiBGaMSGP2qb2dJchIhI6BcQIVUzIp0YtCBHJAAqIEZo9KZ99B7rZ3647qkVkfFNAjNCi6cUArN3ZkuZKRETCpYAYoUXTSwB4s645zZWIiIQr1IAws6VmttHMqs3slhTbY2b2YLD9ZTObM2j7LDNrM7PPhVnnSEwsiDKtJJcNu1vTXYqISKhCCwgzywbuAq4AFgLXmdnCQbvdCDS5+zzgTuCOQdu/AfwqrBqP1pxJBWzfeyDdZYiIhCrMFsQSoNrdt7h7N/AAsGzQPsuA+4Llh4DLzMwAzOwDwFZgbYg1HpVZE/PZsU+XuorI+BZmQMwAapJe1wbrUu7j7r1AMzDJzAqBLwBfHeoDzOwmM6sys6qGhoZRK/xIZk3Kp7GtW9N+i8i4NlYHqb8C3OnubUPt5O73uHulu1eWl5cfn8pItCAAtu9VK0JExq9IiO9dB8xMel0RrEu1T62ZRYASYC9wHnC1mf0LUAr0mVmnu38nxHqHbd7kQgA217eyMLjsVURkvAkzIFYC881sLokguBb4yKB9lgMfA14CrgaecXcHLurfwcy+ArSNlXAAOLm8kEiWsVFXMonIOBZaQLh7r5ndDDwOZAP3uvtaM7sdqHL35cAPgPvNrBrYRyJExrxoJIt5kwt1qauIjGthtiBw9xXAikHrbkta7gSuOcJ7fCWU4o7RwunFPL+pAXcnuPBKRGRcGauD1GPe2+dOorGtm831Q46ji4icsBQQR+n8kycB8JuN9WmuREQkHAqIozRzYj7nzJ7AT1/eQV+fp7scEZFRp4A4BtecU8H2ve1sadS0GyIy/iggjsHZsycA8EbN/jRXIiIy+hQQx+Dk8kIKYxFer2lKdykiIqNOAXEMsrOMC+eVsWLNbjp74ukuR0RkVCkgjtFHz5/NvgPdPLp6V7pLEREZVQqIY3T+yZOYP7mQ+1/alu5SRERGlQLiGJkZ11RW8EZtMzV6RoSIjCMKiFHwnkVTAVixRt1MIjJ+KCBGwexJBSyZM5H7XtxGmx4iJCLjhAJilHzm3fPZ09rFF/57NT96YSuv7dClryJyYgt1NtdM8o6Ty7jxwrnc8/wWHguuaFr5xXdRXhRLc2UiIkdHLYhR9KHKCqLZWUwsiALw4luNaa5IROToKSBG0bzJRaz+yuW88neXURiLcOeTm2jv1piEiJyYFBCjLDcnm0h2FhfMm8S2ve08uLIm3SWJiByVUAPCzJaa2UYzqzazW1Jsj5nZg8H2l81sTrD+3Wb2qpmtCf69NMw6w/Dd689hYkGUV7buY2vjAdbtbEl3SSIiIxLaILWZZQN3Ae8GaoGVZrbc3dcl7XYj0OTu88zsWuAO4MNAI/B+d99pZqeTeK71jLBqDUN2lnHJKeU8/Hodv3pzNwBb/+lKPZ5URE4YYbYglgDV7r7F3buBB4Blg/ZZBtwXLD8EXGZm5u6vu/vOYP1aIM/MTrjLga47b9ZBr9ftSrQiXnyrkeb2nnSUJCIybGEGxAwguQO+lkNbAQP7uHsv0AxMGrTPB4HX3L0rpDpDc+6ciTz6Vxfy6F9dSCTLuP+l7exq7uAj33+Z93/nf3HXk+hEZOwa0/dBmNkiEt1Olx9m+03ATQCzZs1KtUvanT6jBICPXzCH//jfrQPrd+xrZ+OeVhZMLU5XaSIiQwqzBVEHzEx6XRGsS7mPmUWAEmBv8LoCeAT4qLu/leoD3P0ed69098ry8vJRLn90feqy+ZQVxnhgZQ2FsUQuP7uhIc1ViYgcXpgBsRKYb2ZzzSwKXAssH7TPcuBjwfLVwDPu7mZWCjwG3OLuL4RY43FTlJvDT248jw+eXcHymy9g0fRivvnUJv7sx1U8tW5PussTETmEhdkPbmZXAt8EsoF73f0fzOx2oMrdl5tZLnA/8DZgH3Ctu28xsy8BtwKbk97ucnevP9xnVVZWelVVVWjnMtpq9rXz9Sc28r+bG9nX3s09f1LJuxdOSXdZIpJhzOxVd69MuW28DJSeaAHRr6M7zofufomtjQdYfvMFnFReyPa9B1hVs5+rzpquy2JFJFRDBcSYHqTOBHnRbO7+k3N4z53Pc+m/Psc151Twi1U76Y73sa2xnU+/a366SxSRDKWpNsaA6aV5fOl9pzG9JJf/erWW7ngf8yYXctez1QNPqdu8p5VXtu5Lc6UikknUxTTGfP3xjXT0xPnTi+byB1//DaV5USYWRAdusvvilafxYFUN00py+dOLTuLiU4a+emv5Gzt5YXMjd1x95vEoX0ROMBqDOEH95ys7+MfH1jNvSiGnTC7iwarEfYcT8nNwoLMnzpVnTGPltn38nwvm8sArNXz6XfO5PBjszjLjpL9bAUDVl95FWeEJdzO6iIRMATFOvLp9Hz99eQe3vW8hPXHn3Xc+x/72Hibk59CUNHVHliUeg9rVE2dncycAd33kbN575rR0lS4iY5QCYpx6s66ZA129LJpRwh999wU27WmjrDBKvM9pau8hGsli9sR8Nte3URSL8Jl3n8LKrfv4whULmFtWwN62Lu55fgs3XzqPotwcAOJ9zrqdLcwuy6c4WCci45euYhqn+qfxAFh+84V09fSRH8sm24w3avczZ1IBEwqirK7dzw0/XMnXHk1MpFu1fR+nTSumalsTHT1xOnri3Pa+hUSys7jr2Wq+8eSmgff94NkVfOLik4hFspg9qYANu1s4qayQaETXN4iMd2pBZIgXqhu58b6V3HjhXFbXNtPeHSfbjFe2Ja6Mumh+GVefU8E//2oDu4JuqWTRSBb3fXwJ133/d1xx+lS+98fnsKa2mbuerea9Z05j8cxSNuxu5fMPvcG88kJ+fOMS8qNH/vujsa2LwliE3Jxs2rt7eXBlDR85bxaxSPaofw9E5FDqYhIgMaidm3PwL941tc186+nNPL+5ge7ePqKRLL53/dlUzpnIjr3t3PfSNl7b0cSWhgPEIll09fYBiedvv7RlLzX7OlJ+1kfPn82nLpvPpIIoZkZtUzv3vbiN6aV5fPyCuXT39vGdZzbz7WequfbcmfzzB8/kK8vX8qMXt3HJqeV8/IK5A1dodXTH+dcnNpIXzeazl58KgLuzYXcrp00b+WSHNfvaaensYdH0kiPvLDLOKSDkiLp647xVf4DyohjlRb+/2sndMTNe2bqPv39sHdlZRn1LF3X7O5hUEOXr15xFQ1sXf/vQanJzsnjoz9/Bw6/Vce8LiZlrT5lSSHV9G31H+DG74vSpPL2hnu4ggAAuXziFF6obKS+KsW1v4n6Qf//js5lTVsCL1Xu5/dF1/PRPz+MdJ0/izboWTp9RPOSd50+t28N9L23jt5sbAdjyj1eSlaU71SWzKSBkVLV19eLuFMYiA7+QtzS0Mb00j9ycbDp74nz1l+v4z1d2HHTcssXT+c3GBpo7EldcfW3ZItq64tzx6w0UxiKcNq2ILyxdQE1TO5/9+RsDoZKbk8VfXjKPf00aG0lWkpcz8J5ffv9CzqwoYX97D6fPKGFKcS4Af/fIGn728sH1fOX9C7nhgrls33uAv35wFadOLeL2ZaeTk33w+Ep/SI629u5evvHEJs47adKw5+Hqiffxdw+v4YYL5hz3FlBzew8l+bpwYbxRQEha7G/v5ndb9lIYy2HvgS6WLZ5BQ2sXu5s7OaMi8cvN3Vm7s4VF0w/+6/83G+vZtCfRhbRoegkTC6I8uHIHd/x6I33utHfHyY1k0dLZO2QNi2eWUjEhj18Hj339+w+czi0PrxnYPrkoRn3r759F9aX3nsb1583mm09twsy4/rxZ/OF3X6By9kS+fd3byM4yWjp6uP9325lTVkC8r48fvrCNdTtb+PJVi7ju3Jn86MVtnFxeyIXzy8jJzuLR1Tt5ZkM9ty87nWwzXt/RxM7mTu749QYags/+zkfexvvOnD5Qx+Y9rXziJ6/ytWWnc8G8MgB2NXfwNw++wUtb9gLwzGcv5qTyQtq6ern7ubc4ZUoRWxoO8MvVO7n1igVcdlrq0OnqjWMY8T4nFskaVitq/a4WrvjWb/nWtYtZtjj8p/8md4d2dMf5zIOv88lL5rF4Zmmon/vkuj1MKY5xZkW4nzOWKCBkXOmN99Hc0UNeNJvePufZDfVMLc5lwdRibn1kNSvW7B7Yd8mcidTt76CxrYvHPnUR8yYXAvDSW3u5/j9+N9BKWTC1iNbOXur2px5T6VcUi9DaNXQo9SvJy2FuWQGravYfdp/3njmNx1bvAuCP3z6L17bvp6MnztbGA0DipsgPnzuL/61u4M26lkOOz83JorOn75D12VnGNz+8mMJYhJ+9soPNe1opzsvhvWdM459+teGgfRfPLOWTl5zMga5ent/UQGl+lJbOHqYU5/LM+nquOGMqXb19fO83b7FwWjErPn0R7d291Ozr4NSpRbR39w5ckPBGzX6mFOcytSR34P0ffq2W1bXNnDN7Av/1ai3vOm0yf/i2GQOXVidzd/76wVWseHM3T//NxUwpzuX2R9fyk98lWn/fvf5srjxjGvWtncQi2ZTkpW7RfOl/1nBmRSkfqpyZcnsqfX0+cGPptn9+77CPG1z/iTbBpgJCMo67487AX8fxPid70F/KDa1dZBl8/YlNLFs8nYbWLv79ubcoycvhrJmlPLp6J+1dcb7x4cXc/9J2uuN99PU5b9Ts59Pvmk+8z1k8s5RpJXn89OXt3P38lmHVVpQb4YZ3zGFaSR7XnjuTh1+v43P/9QYAp04pYmvjAc6sKGHp6VP51tObae3s5dQpRSyZO5FJhVEmF+VSlBthW+OBg7rdbrxwLotnltLRHeerv1zLge74iL9vhbEI7j7ksX/4thms39XCht2tFOdGONAdZ+miqWzfd4A361qIRrK4+Q/msbXxAM9sqB/o/ktWXhTjrIoSnlqfmMF/1sR83n/WNCJZWXzr6cQs/xfOK2PjntaBVla/ytkTqNrexIKpRfzf9y3kl2/spHLORCYVRLn4lHJ2tXRywT8/A8DWf7qSfQe6+dbTm7ni9MTVdk+s280lp04eCJevP74Rx/mP324duAhj9Vcup70rTk1TO22dvZxUXkBtUwfvOHnSIQHQE++jur6Nf3tmM1saDvDgJ87nhepGLl0weaAVFO9zNu1pZcHUooHjO7rjvPhWYozt9KTuwqws40BXL7k52Yf8zA4W73OyjGMKJQWEyFHo6I4TybZDxiT6+jxlt0xrZw9FuTm4Ow+/VkdBLJtLTp3M42t3s2TuRB5bvYsb3jGH7njfIZcAv7p9H79as5vPLz2V7t6+gfGdtq5euv9EnXMAAAm3SURBVHriTDrMNCnxPmdPSyexSNZB+9S3drK6ppn7f7edT102j5PKCtnd0skTa/dwRkUxdU0dfOjcmXT29LFjbzs7mzvIy8nm7SdNIhrJIt7n1Oxrp2JCHht2t/Lwa3WcO2cCv1i1k99sqqezJ3HFW1+fYwY9cWduWQGXLZjM5vo2ntvUQFEswsWnlrN4Zil7WjpZVbOff7vubGqa2vn7R9exblcLPXHnpPICZpTmDVw8sGBqEc0dPexq7mTe5EJuWboAB3768nbmTy7k+7/dmvJ7ATClOIY7A92GU4pj7Gk59HH2U4tzyc5KdLPtbjn0su4L55XxwluN9P96NAN3uPiUcva0dNLeHefD585k1sR8/uGx9SnfY3JRjC++9zTOnTORLz6yhmc3NrBgahEfv2AOjW3dPL+pgZeDCTjff9Z0tu89QCTLmDkxn1+s2snU4lw+ct4sVtfuZ+OeVuaWFfLO+WXMLSugu7ePrt4+/ulX6/mjsyv4wtIFh/2eHIkCQkRGTWtnD9v3trNwWjG9fc5rO5r46cs7+Ic/PJ3iICDX7UrcUJkXPfz9LO5OV28fOdlZZGcZL77VSF8fnH/yJJ7f3MALmxu58aK5TCvJO+i4zXtaqZiQz+s7mqhv7eLMihK6431s3N3Klx55k7buXj777lOo29/JL1bV0dET5x8+cAZbGtrIyjJikSye29TA6tpmAM6aWcq7Fkzm9Zr9TC/N5dkNDdTt7+DUKUXMnJjPU+uHfuJjeVGMLyxdwDmzJ/BmXTP/+coOXnxr77C+lx88u4JoJIsHVu4YCKPCWIT3nTmN6vo2qrY3AbB00VS2NLaxaU/bQcf3B9clp5bzo48vGdZnDqaAEJGMUNvUTndvHyeVJ8aaeuJ91DV1MKes4KD93J3Gtm7KCqOHdM/8ZmM9L721lz9750mUFcZ4ev0e8qMRFk4vZvmqOrKzsphcFGNueQEd3XHmlBUMPGe+X2dPnN3Nnezv6GHl1n3Mm1LIxfPL2dLYxrMbGrj0tMn0xPtYMDVxH8/u5k6yDOLuTCqIEY1k4e7892t1zC3L55zZE4FEONY0tVMQjfDqjibeddoUfvnGTvKi2fzFJfOO6numgBARkZSGCohQJ9Qxs6VmttHMqs3slhTbY2b2YLD9ZTObk7Tt1mD9RjN7T5h1iojIoUILCDPLBu4CrgAWAteZ2cJBu90INLn7POBO4I7g2IXAtcAiYCnw3eD9RETkOAmzBbEEqHb3Le7eDTwALBu0zzLgvmD5IeAyS3QILgMecPcud98KVAfvJyIix0mYATEDqEl6XRusS7mPu/cCzcCkYR6Lmd1kZlVmVtXQ0DCKpYuIyAk9qb+73+Pule5eWV4+9LOZRURkZMIMiDog+T73imBdyn3MLAKUAHuHeayIiIQozIBYCcw3s7lmFiUx6Lx80D7LgY8Fy1cDz3jiutvlwLXBVU5zgfnAKyHWKiIig4T2yFF37zWzm4HHgWzgXndfa2a3A1Xuvhz4AXC/mVUD+0iECMF+PwfWAb3AX7r7yCeWERGRozZubpQzswZg+1EeXgY0jmI5JwKdc2bQOWeGYznn2e6echB33ATEsTCzqsPdSThe6Zwzg845M4R1zif0VUwiIhIeBYSIiKSkgEi4J90FpIHOOTPonDNDKOesMQgREUlJLQgREUkp4wPiSFOSn6jM7F4zqzezN5PWTTSzJ81sc/DvhGC9mdm3g+/BajM7O32VHx0zm2lmz5rZOjNba2afDtaP53PONbNXzOyN4Jy/GqyfG0yfXx1Mpx8N1h92ev0TjZllm9nrZvZo8Hpcn7OZbTOzNWa2ysyqgnWh/2xndEAMc0ryE9WPSEyVnuwW4Gl3nw88HbyGxPnPD75uAr53nGocTb3AZ919IfB24C+D/5bj+Zy7gEvd/SxgMbDUzN5OYtr8O4Np9JtITKsPh5le/wT1aWB90utMOOc/cPfFSZezhv+z7e4Z+wWcDzye9PpW4NZ01zWK5zcHeDPp9UZgWrA8DdgYLN8NXJdqvxP1C/gF8O5MOWcgH3gNOI/EDVORYP3AzziJWQ3OD5YjwX6W7tqP4lwrgl+IlwKPApYB57wNKBu0LvSf7YxuQTDMacXHkSnuvitY3g1MCZbH1fch6EZ4G/Ay4/ycg66WVUA98CTwFrDfE9Pnw8Hndbjp9U803wT+FugLXk9i/J+zA0+Y2atmdlOwLvSf7dDmYpKxzd3dzMbdJWxmVgj8N/AZd2+xpAfSj8dz9sQcZYvNrBR4BFiQ5pJCZWbvA+rd/VUzuyTd9RxHF7p7nZlNBp40sw3JG8P62c70FkSmTSu+x8ymAQT/1gfrx8X3wcxySITDT9394WD1uD7nfu6+H3iWRPdKaTB9Phx8XoebXv9EcgFwlZltI/GUykuBbzG+zxl3rwv+rSfxh8ASjsPPdqYHxHCmJB9PkqdX/xiJfvr+9R8Nrn54O9Cc1HQ9IViiqfADYL27fyNp03g+5/Kg5YCZ5ZEYc1lPIiiuDnYbfM6pptc/Ybj7re5e4e5zSPz/+oy7X884PmczKzCzov5l4HLgTY7Hz3a6B1/S/QVcCWwi0Xf7xXTXM4rn9Z/ALqCHRB/kjST6Xp8GNgNPARODfY3E1VxvAWuAynTXfxTneyGJftrVwKrg68pxfs5nAq8H5/wmcFuw/iQSz0+pBv4LiAXrc4PX1cH2k9J9Dsd4/pcAj473cw7O7Y3ga23/76nj8bOtO6lFRCSlTO9iEhGRw1BAiIhISgoIERFJSQEhIiIpKSBERCQlBYTICJhZPJhRs/9r1GYANrM5ljT7rki6aaoNkZHpcPfF6S5C5HhQC0JkFATz9f9LMGf/K2Y2L1g/x8yeCeblf9rMZgXrp5jZI8GzHN4ws3cEb5VtZt8Pnu/wRHCHtEhaKCBERiZvUBfTh5O2Nbv7GcB3SMw4CvBvwH3ufibwU+DbwfpvA8954lkOZ5O4QxYSc/jf5e6LgP3AB0M+H5HD0p3UIiNgZm3uXphi/TYSD+/ZEkwauNvdJ5lZI4m5+HuC9bvcvczMGoAKd+9Keo85wJOeeAAMZvYFIMfd/z78MxM5lFoQIqPHD7M8El1Jy3E0TihppIAQGT0fTvr3pWD5RRKzjgJcD/w2WH4a+CQMPPSn5HgVKTJc+utEZGTygie49fu1u/df6jrBzFaTaAVcF6z7K+CHZvZ5oAH4eLD+08A9ZnYjiZbCJ0nMvisyZmgMQmQUBGMQle7emO5aREaLuphERCQltSBERCQltSBERCQlBYSIiKSkgBARkZQUECIikpICQkREUlJAiIhISv8ffmzotnaKHSUAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = range(1, num_epochs+1)\n",
        "y = losses\n",
        "plt.plot(x, y)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BMctmd9pXSiA"
      },
      "execution_count": 6,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Coordinate_to_RGB (without positional encoding).ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}